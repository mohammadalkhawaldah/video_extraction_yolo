import os
import glob
import cv2
from collections import defaultdict, deque
from ultralytics import YOLO

# =====================================================
# CONFIG
# =====================================================
MODEL_PATH = r"C:\Users\moham\OneDrive\Documents\clips_extraction_by_yolo\best.pt"
VIDEO_FOLDER = r"C:\Users\moham\OneDrive\Documents\clips_extraction_by_yolo\test_videos"

CONFIDENCE = 0.35
IOU = 0.5
DEVICE = "cpu"          # ØºÙŠÙ‘Ø±Ù‡Ø§ Ø¥Ù„Ù‰ 0 Ø¥Ø°Ø§ CUDA Ù…ØªÙˆÙØ±

# Performance
RESIZE_TO = (640, 640)
PROCESS_EVERY_N_FRAMES = 2

# Event logic
WINDOW_SIZE = 20                # Ù†Ø£Ø®Ø° ÙÙ‚Ø· Ø¢Ø®Ø± 20 ÙØ±ÙŠÙ…
MIN_FRAMES_PER_CLASS = 5        # â— Ø´Ø±Ø·Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
EXIT_MISSED_FRAMES = 10         # Ø§Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† Ø§Ù„Ù…Ø´Ù‡Ø¯

SHOW = True

# =====================================================
# Helpers
# =====================================================
def sec_to_hhmmss_msec(seconds: float) -> str:
    ms = int((seconds - int(seconds)) * 1000)
    s = int(seconds) % 60
    m = (int(seconds) // 60) % 60
    h = (int(seconds) // 3600)
    return f"{h:02d}:{m:02d}:{s:02d}.{ms:03d}"

def frame_to_time(frame_index: int, fps: float) -> float:
    return frame_index / fps if fps > 0 else 0.0

# =====================================================
# MAIN
# =====================================================
def main():
    model = YOLO(MODEL_PATH)
    print("âœ… Model loaded")
    print("ðŸŽ¯ Event-Based Classification (Last 20 Frames + Min 5 Frames Rule)\n")

    video_files = glob.glob(os.path.join(VIDEO_FOLDER, "*.mp4"))
    if not video_files:
        raise FileNotFoundError("âŒ No videos found")

    if SHOW:
        cv2.namedWindow("YOLO Event-Based (Stable Classes)", cv2.WINDOW_NORMAL)

    for video_path in video_files:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            continue

        fps = cap.get(cv2.CAP_PROP_FPS) or 25.0

        # Track data Ù„ÙƒÙ„ ID
        track_data = defaultdict(lambda: {
            "history": deque(maxlen=WINDOW_SIZE),  # (class_id, conf)
            "last_seen": None,
            "finalized": False
        })

        processed_frame_idx = 0
        original_frame_idx = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            original_frame_idx += 1
            if original_frame_idx % PROCESS_EVERY_N_FRAMES != 0:
                continue

            processed_frame_idx += 1
            frame_small = cv2.resize(frame, RESIZE_TO)

            # Tracking
            results = model.track(
                source=frame_small,
                conf=CONFIDENCE,
                iou=IOU,
                device=DEVICE,
                persist=True,
                verbose=False
            )

            r = results[0]
            names = r.names

            # ØªØ­Ø¯ÙŠØ« Ø¢Ø®Ø± 20 ÙØ±ÙŠÙ…
            if r.boxes is not None and r.boxes.id is not None:
                ids = r.boxes.id.int().tolist()
                clss = r.boxes.cls.int().tolist()
                confs = r.boxes.conf.tolist()

                for tid, cid, cf in zip(ids, clss, confs):
                    d = track_data[tid]
                    if d["finalized"]:
                        continue

                    d["history"].append((cid, float(cf)))
                    d["last_seen"] = processed_frame_idx

            # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† Ø§Ù„Ù…Ø´Ù‡Ø¯
            for tid, d in list(track_data.items()):
                if d["finalized"] or d["last_seen"] is None:
                    continue

                if processed_frame_idx - d["last_seen"] > EXIT_MISSED_FRAMES:
                    scores = defaultdict(float)
                    counts = defaultdict(int)

                    # ØªØ¬Ù…ÙŠØ¹ ÙÙ‚Ø· Ø¢Ø®Ø± 20 ÙØ±ÙŠÙ…
                    for cid, cf in d["history"]:
                        scores[cid] += cf
                        counts[cid] += 1

                    # â— ØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ ÙƒÙ„Ø§Ø³ Ø£Ù‚Ù„ Ù…Ù† 5 ÙØ±ÙŠÙ…Ø§Øª
                    valid_classes = [
                        cid for cid in scores
                        if counts[cid] >= MIN_FRAMES_PER_CLASS
                    ]

                    if valid_classes:
                        best_class_id = max(
                            valid_classes,
                            key=lambda c: (scores[c], counts[c])
                        )

                        event_time_sec = frame_to_time(
                            d["last_seen"] * PROCESS_EVERY_N_FRAMES, fps
                        )
                        event_time_str = sec_to_hhmmss_msec(event_time_sec)

                        print(
                            f"ðŸšš EVENT | track_id={tid} | "
                            f"class={names[int(best_class_id)]} | "
                            f"timestamp={event_time_str}"
                        )

                    d["finalized"] = True

            # Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
            if SHOW:
                annotated = r.plot()
                cv2.imshow("YOLO Event-Based (Stable Classes)", annotated)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    cap.release()
                    cv2.destroyAllWindows()
                    return

        # Ø¥Ù†Ù‡Ø§Ø¡ Ø£ÙŠ ID Ù…ØªØ¨Ù‚Ù Ø¹Ù†Ø¯ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        for tid, d in track_data.items():
            if d["finalized"] or not d["history"]:
                continue

            scores = defaultdict(float)
            counts = defaultdict(int)

            for cid, cf in d["history"]:
                scores[cid] += cf
                counts[cid] += 1

            valid_classes = [
                cid for cid in scores
                if counts[cid] >= MIN_FRAMES_PER_CLASS
            ]

            if valid_classes:
                best_class_id = max(
                    valid_classes,
                    key=lambda c: (scores[c], counts[c])
                )

                event_time_sec = frame_to_time(
                    d["last_seen"] * PROCESS_EVERY_N_FRAMES, fps
                )
                event_time_str = sec_to_hhmmss_msec(event_time_sec)

                print(
                    f"ðŸšš EVENT | track_id={tid} | "
                    f"class={names[int(best_class_id)]} | "
                    f"timestamp={event_time_str}"
                )

        cap.release()

    if SHOW:
        cv2.destroyAllWindows()

    print("\nâœ… Processing completed")

# =====================================================
if __name__ == "__main__":
    main()
